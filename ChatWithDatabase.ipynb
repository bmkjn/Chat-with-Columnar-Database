{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "Oma0jt-eE_hG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "\n",
        "# import prompt template\n",
        "from langchain import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HveAh5boE_hK",
        "outputId": "c83fd478-a944-4958-d906-8d1f5252891d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/nb/6qvvb9dj30l_kxkvsvmsq25m0000gn/T/ipykernel_3532/1118296231.py:1: DtypeWarning: Columns (0,2,3,5,7,8,9,10,11,12,13,14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"MASTER_FILES/Master_Final.csv\")\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"MASTER_FILES/Master_Final.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_-EqkJSE_hK",
        "outputId": "18773005-49fc-4983-f90a-f2a6f054302e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Scheduled_Date', 'Brand', 'City', 'Ad_Lang', 'Amount', 'ActivityName',\n",
            "       'Medium', 'State', 'Market', 'PO_Date', 'CreatedBy', 'Agency',\n",
            "       'ApprovedBy', 'Spot_Type', 'Parent Network', 'Channel', 'Caption'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "seoXdbUuE_hK"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv(dotenv_path='/Users/bhumika/Downloads/venv/bi_chatbot/.env')\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"pr-timely-slaw-83\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "oxOcb8I-E_hL",
        "outputId": "d7bf1902-a5a4-4ec8-83ce-e7133d8edde5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1724149505.366894   62965 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'I am Gemini, a multimodal AI language model developed by Google. I am designed to understand and generate human language, answer questions, and provide information on a wide range of topics.\\n\\nHere are some of the things I can do:\\n\\n* **Answer questions:** I can answer questions on a wide range of topics, including history, science, current events, and more.\\n* **Provide information:** I can provide information on a wide range of topics, including weather, sports, stocks, and more.\\n* **Generate text:** I can generate text in a variety of styles, including news articles, stories, poems, and more.\\n* **Translate languages:** I can translate text between over 100 languages.\\n* **Summarize text:** I can summarize text into a shorter, more concise version.\\n* **Answer questions in a conversational way:** I can answer questions in a conversational way, making it easy to interact with me.\\n\\nI am still under development, but I am learning new things every day. I am excited to see how I can help people in the future.'"
            ]
          },
          "execution_count": 260,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm = GoogleGenerativeAI(model=\"gemini-pro\",temperature=0.1)\n",
        "llm.invoke(\"Who are you? and what can you do?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "869Z1HkXE_hM",
        "outputId": "69aa3fc7-c39b-47f3-f599-98c115ca41a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Enhanced Question': 'What was the total spending on Radio Mirchi in Jaipur during June?', 'Relevant Columns': ['Medium', 'State', 'City', 'Amount', 'Scheduled_Date']}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# create the prompt-1\n",
        "prompt_template: str = \"\"\"\n",
        "\n",
        "You are a query enhancing agent. You have to work with the query provided by the user : {query}.\n",
        "The user wants to inquire about information from the ad campaigns dataset, which contain the spending\n",
        "and other information of different mediums which are represented by Medium column, namely - TV , Print , Radio ,  Digital, OOH and BTL.\n",
        "The dataset contains following columns and description -\n",
        "\n",
        "\"Brand\": \"The brand associated with the ad campaign.\",\n",
        "\"Agency\": \"The advertising agency managing the ad campaign.\",\n",
        "\"CreatedBy\": \"The individual or entity who created the document.\",\n",
        "\"PO_Date\": \"The date the purchase order was created.\",\n",
        "\"Market\": \"The market targeted by the ad campaign.\",\n",
        "\"Channel\": \"The channel through which the ad is broadcasted or published\",\n",
        "\"Parent Network\": \"The parent network associated with the channel.\",\n",
        "\"Caption\": \"The caption or title of the ad.\",\n",
        "\"Ad_Lang\": \"The language in which the ad is presented.\",\n",
        "\"Scheduled_Date\": \"The scheduled date for the ad campaign.\",\n",
        "\"Amount\": \"The total gross amount spent on the ad campaign.\",\n",
        "\"ApprovedBy\": \"The individual or entity who approved the document.\",\n",
        "\"Spot_Type\": \"The type of ad spot (e.g., prime time, regular, etc.).\",\n",
        "\"Medium\": \"The medium of the ad campaign (e.g., TV, radio, digital, print, OOH, BTL).\",\n",
        "\"State\": \"The state where the ad campaign is being targeted.\",\n",
        "\"City\": \"The city where the ad campaign is being targeted.\",\n",
        "'ActivityName': 'The name or title of the specific ad campaign activity.'\n",
        "\n",
        "\n",
        "Now you have to understand the query and see what are the relevant columns that would be required to solve the query.\n",
        "Then using those relevant columns enhance the query so that there is no key value error when that query is used to generate code.\n",
        "\n",
        "Return your answer in dictionary format as below -\n",
        "\n",
        "\"Enhanced Question\" : the updated query,\n",
        "\"Relevant Columns\": relevant columns in a list\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template=prompt_template)\n",
        "\n",
        "# format the prompt to add variable values\n",
        "prompt_formatted_str: str = prompt.format(\n",
        "    query=\"What was the spend for Radio Mirchi Jaipur in June month?\")\n",
        "\n",
        "answer = llm.invoke(prompt_formatted_str)\n",
        "\n",
        "import ast\n",
        "# Convert the string to a dictionary\n",
        "def convert_string_to_dict(input_string):\n",
        "    # Use ast.literal_eval to safely evaluate the string as a dictionary\n",
        "    dictionary = ast.literal_eval(input_string)\n",
        "    return dictionary\n",
        "\n",
        "# Call the function and print the result\n",
        "result_dict = convert_string_to_dict(answer)\n",
        "enhanced_question = result_dict['Enhanced Question']\n",
        "relevant_columns = result_dict['Relevant Columns']\n",
        "\n",
        "print(result_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkAdAa5QC8GA",
        "outputId": "a50c4b7e-7242-4257-f045-8e22a2079b3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Relevant Columns': ['Amount', 'State', 'Market', 'Channel', 'Scheduled_Date']}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# create the prompt-2\n",
        "prompt_template: str = \"\"\"\n",
        "\n",
        "You are a query enhancing agent. You have to work with the query provided by the user : {query}.\n",
        "The user wants to inquire about information from the ad campaigns dataset, which contain the spending\n",
        "and other information of different mediums which are represented by Medium column.\n",
        "The dataset contains following columns and description -\n",
        "\n",
        "\"Brand\": \"The brand associated with the ad campaign.\",\n",
        "\"Agency\": \"The advertising agency managing the ad campaign.\",\n",
        "\"CreatedBy\": \"The individual or entity who created the document.\",\n",
        "\"PO_Date\": \"The date the purchase order was created.\",\n",
        "\"Market\": \"The market targeted by the ad campaign.\",\n",
        "\"Channel\": \"This column may include the name of a TV channel, radio station, newspaper, or social media platform through which the ad is broadcasted or published.\",\n",
        "\"Parent Network\": \"The parent network associated with the channel.\",\n",
        "\"Caption\": \"The caption or title of the ad.\",\n",
        "\"Ad_Lang\": \"The language in which the ad is presented.\",\n",
        "\"Scheduled_Date\": \"The scheduled date for the ad campaign.\",\n",
        "\"Amount\": \"The total gross amount spent on the ad campaign.\",\n",
        "\"ApprovedBy\": \"The individual or entity who approved the document.\",\n",
        "\"Spot_Type\": \"The type of ad spot (e.g., prime time, regular, etc.).\",\n",
        "\"Medium\": \"The medium of the ad campaign (e.g., TV, radio, digital, print, OOH, BTL).\",\n",
        "\"State\": \"The state where the ad campaign is being targeted.\",\n",
        "\"City\": \"The city where the ad campaign is being targeted.\",\n",
        "'ActivityName': 'The name or title of the specific ad campaign activity.'\n",
        "\n",
        "\n",
        "You need to analyze the query and, using general knowledge and the descriptions provided for each column, examine the columns to determine which ones are relevant to solve the query.\n",
        "\n",
        "For example, if the user query is \"In what languages is Lokmat newspaper available?\"\n",
        "The required columns would be \"Ad_Lang\" for languages and \"Channel\" or \"Parent Network\"\n",
        "for Lokmat newspaper.\n",
        "\n",
        "Another example, if the user query is \"What was the spend for Jaipur West for Radio Mirchi in June month?\"\n",
        "The required columns would be \"Amount\" for spend, \"State\" for Jaipur, \"Market\" for West, \"Channel\" or \"Parent Network\" for Radio Mirchi, and \"Scheduled_Date\" for June.\n",
        "\n",
        "Therefore, you need to analyze every word in the user query to determine which columns are necessary from the given options.\n",
        "\n",
        "Return your answer in dictionary format as below -\n",
        "\"Relevant Columns\": relevant columns in a list\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template=prompt_template)\n",
        "\n",
        "# format the prompt to add variable values\n",
        "prompt_formatted_str: str = prompt.format(\n",
        "    query=\"What was the spend for Jaipur West for Radio Mirchi in June month?\")\n",
        "\n",
        "answer = llm.invoke(prompt_formatted_str)\n",
        "\n",
        "import ast\n",
        "# Convert the string to a dictionary\n",
        "def convert_string_to_dict(input_string):\n",
        "    # Use ast.literal_eval to safely evaluate the string as a dictionary\n",
        "    dictionary = ast.literal_eval(input_string)\n",
        "    return dictionary\n",
        "\n",
        "# Call the function and print the result\n",
        "result_dict = convert_string_to_dict(answer)\n",
        "relevant_columns = result_dict['Relevant Columns']\n",
        "\n",
        "print(result_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krqDnofINaoI",
        "outputId": "8cf762b9-444c-4283-c642-cbd2fd60df46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Relevant Columns': ['Channel', 'Ad_Lang']}\n"
          ]
        }
      ],
      "source": [
        "# create the prompt-2\n",
        "prompt_template: str = \"\"\"\n",
        "\n",
        "You are a query enhancing agent. You have to work with the query provided by the user : {query}.\n",
        "The user wants to inquire about information from the ad campaigns dataset, which contain the spending\n",
        "and other information of different mediums which are represented by Medium column.\n",
        "The dataset contains following columns and description -\n",
        "\n",
        "\"Brand\": \"The brand associated with the ad campaign.\",\n",
        "\"Agency\": \"The advertising agency managing the ad campaign.\",\n",
        "\"CreatedBy\": \"The individual or entity who created the document.\",\n",
        "\"PO_Date\": \"The date the purchase order was created.\",\n",
        "\"Market\": \"The market targeted by the ad campaign.\",\n",
        "\"Channel\": \"This column may include the name of a TV channel, radio station, newspaper, or social media platform through which the ad is broadcasted or published.\",\n",
        "\"Parent Network\": \"The parent network associated with the channel.\",\n",
        "\"Caption\": \"The caption or title of the ad.\",\n",
        "\"Ad_Lang\": \"The language in which the ad is presented.\",\n",
        "\"Scheduled_Date\": \"The scheduled date for the ad campaign.\",\n",
        "\"Amount\": \"The total gross amount spent on the ad campaign.\",\n",
        "\"ApprovedBy\": \"The individual or entity who approved the document.\",\n",
        "\"Spot_Type\": \"The type of ad spot (e.g., prime time, regular, etc.).\",\n",
        "\"Medium\": \"The medium of the ad campaign (e.g., TV, radio, digital, print, OOH, BTL).\",\n",
        "\"State\": \"The state where the ad campaign is being targeted.\",\n",
        "\"City\": \"The city where the ad campaign is being targeted.\",\n",
        "'ActivityName': 'The name or title of the specific ad campaign activity.'\n",
        "\n",
        "\n",
        "You need to analyze the query and, using general knowledge and the descriptions provided for each column, examine the columns to determine which ones are relevant to solve the query.\n",
        "\n",
        "For example, if the user query is \"In what languages is Lokmat newspaper available?\"\n",
        "The required columns would be \"Ad_Lang\" for languages and \"Channel\" or \"Parent Network\"\n",
        "for Lokmat newspaper.\n",
        "\n",
        "Another example, if the user query is \"What was the spend for Jaipur West for Radio Mirchi in June month?\"\n",
        "The required columns would be \"Amount\" for spend, \"State\" for Jaipur, \"Market\" for West, \"Channel\" or \"Parent Network\" for Radio Mirchi, and \"Scheduled_Date\" for June.\n",
        "\n",
        "Therefore, you need to analyze every word in the user query to determine which columns are necessary from the given options.\n",
        "\n",
        "Return your answer in dictionary format as below -\n",
        "\"Relevant Columns\": relevant columns in a list\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template=prompt_template)\n",
        "\n",
        "# format the prompt to add variable values\n",
        "prompt_formatted_str: str = prompt.format(\n",
        "    query=\"In what languages is EENADU Newspaper available\")\n",
        "\n",
        "answer = llm.invoke(prompt_formatted_str)\n",
        "\n",
        "import ast\n",
        "# Convert the string to a dictionary\n",
        "def convert_string_to_dict(input_string):\n",
        "    # Use ast.literal_eval to safely evaluate the string as a dictionary\n",
        "    dictionary = ast.literal_eval(input_string)\n",
        "    return dictionary\n",
        "\n",
        "# Call the function and print the result\n",
        "result_dict = convert_string_to_dict(answer)\n",
        "relevant_columns = result_dict['Relevant Columns']\n",
        "\n",
        "print(result_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-k3_p4YC8Xd",
        "outputId": "0ceef549-3e79-43a0-f731-2e93a83d4482"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Enhanced Question': 'What is the Market for the top spent Channel?', 'Relevant Columns': ['Market', 'Channel', 'Amount']}\n"
          ]
        }
      ],
      "source": [
        "# create the prompt-3\n",
        "prompt_template: str = \"\"\"\n",
        "\n",
        "You are a query enhancing agent. You have to work with the query provided by the user : {query}.\n",
        "The user wants to inquire about information from the ad campaigns dataset, which contain the spending\n",
        "and other information of different mediums which are represented by Medium column.\n",
        "The dataset contains following columns and description -\n",
        "\n",
        "\"Brand\": \"The brand associated with the ad campaign.\",\n",
        "\"Agency\": \"The advertising agency managing the ad campaign.\",\n",
        "\"CreatedBy\": \"The individual or entity who created the document.\",\n",
        "\"PO_Date\": \"The date the purchase order was created.\",\n",
        "\"Market\": \"The market targeted by the ad campaign.\",\n",
        "\"Channel\": \"This column may include the name of a TV channel, radio station, newspaper, or social media platform through which the ad is broadcasted or published.\",\n",
        "\"Parent Network\": \"The parent network associated with the channel.\",\n",
        "\"Caption\": \"The caption or title of the ad.\",\n",
        "\"Ad_Lang\": \"The language in which the ad is presented.\",\n",
        "\"Scheduled_Date\": \"The scheduled date for the ad campaign.\",\n",
        "\"Amount\": \"The total gross amount spent on the ad campaign.\",\n",
        "\"ApprovedBy\": \"The individual or entity who approved the document.\",\n",
        "\"Spot_Type\": \"The type of ad spot (e.g., prime time, regular, etc.).\",\n",
        "\"Medium\": \"The medium of the ad campaign (e.g., TV, radio, digital, print, OOH, BTL).\",\n",
        "\"State\": \"The state where the ad campaign is being targeted.\",\n",
        "\"City\": \"The city where the ad campaign is being targeted.\",\n",
        "'ActivityName': 'The name or title of the specific ad campaign activity.'\n",
        "\n",
        "\n",
        "You need to analyze the query and, using general knowledge and the descriptions provided for each column, examine the columns to determine which ones are relevant to solve the query.\n",
        "\n",
        "For example, if the user query is \"In what languages is Lokmat newspaper available?\"\n",
        "The required columns would be \"Ad_Lang\" for languages and \"Channel\" or \"Parent Network\"\n",
        "for Lokmat newspaper.\n",
        "\n",
        "Another example, if the user query is \"What was the spend for Jaipur West for Radio Mirchi in June month?\"\n",
        "The required columns would be \"Amount\" for spend, \"State\" for Jaipur, \"Market\" for West, \"Channel\" or \"Parent Network\" for Radio Mirchi, and \"Scheduled_Date\" for June.\n",
        "\n",
        "Therefore, you need to analyze every word in the user query to determine which columns are necessary from the given options.\n",
        "Then using those relevant columns enhance the query so that there is no key value error when that query is used to generate code.\n",
        "\n",
        "Return your answer in dictionary format as below -\n",
        "\"Enhanced Question\" : the updated query,\n",
        "\"Relevant Columns\": relevant columns in a list\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template=prompt_template)\n",
        "\n",
        "# format the prompt to add variable values\n",
        "prompt_formatted_str: str = prompt.format(\n",
        "    query=\"What is the Market for top spent Channel?.\")\n",
        "\n",
        "answer = llm.invoke(prompt_formatted_str)\n",
        "\n",
        "import ast\n",
        "# Convert the string to a dictionary\n",
        "def convert_string_to_dict(input_string):\n",
        "    # Use ast.literal_eval to safely evaluate the string as a dictionary\n",
        "    dictionary = ast.literal_eval(input_string)\n",
        "    return dictionary\n",
        "\n",
        "# Call the function and print the result\n",
        "result_dict = convert_string_to_dict(answer)\n",
        "enhanced_question = result_dict['Enhanced Question']\n",
        "relevant_columns = result_dict['Relevant Columns']\n",
        "\n",
        "print(result_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "bfq0npSUE_hN",
        "outputId": "f18daef2-b4c6-49fa-dd95-23c672dae86e"
      },
      "outputs": [],
      "source": [
        "categorical_columns = ['Brand', 'Agency', 'CreatedBy', 'Market', 'Channel',\n",
        "                        'Parent Network', 'Caption', 'Ad_Lang','ApprovedBy',\n",
        "                        'Spot_Type', 'Medium', 'State', 'City']\n",
        "\n",
        "# Identify categorical columns in the relevant columns\n",
        "categorical_relevant_columns = [col for col in relevant_columns if col in categorical_columns]\n",
        "\n",
        "# Get unique values for categorical columns\n",
        "unique_values = {}\n",
        "for col in categorical_relevant_columns:\n",
        "    unique_values[col] = df[col].unique()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko5zPHBoHT3Z"
      },
      "source": [
        "### Prompt Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {
        "id": "Tdkv1OMTHiKf"
      },
      "outputs": [],
      "source": [
        "# df_description = '''\n",
        "# You are a data analysis agent specializing in helping non-technical users understand and interpret data accurately.\n",
        "# Your main objective is to provide clear and concise answers to user's questions in the form of strings only, without generating any graphs or visual aids.\n",
        "# Your role involves interpreting user's queries, which may include spelling or capitalization errors, and using the closest matching correct values from the relevant column and rows to ensure accurate analysis.\n",
        "# The data you work with is a single dataframe representing ad campaigns, which includes various relevant columns.\n",
        "# One key column is Medium, which represents the type of medium in which the ad campaign was displayed, which consists of Print, TV (television), Radio, Digital, OOH (outdoor), and BTL (below the line marketing).\n",
        "# This data is related to a user who has spent money on ad campaigns across different brands, indicated by the column called Brand, which shows the brand for which the money was spent.\n",
        "# The dataframe also includes a column called Amount that indicates the amount spent on the campaign.\n",
        "# Additionally, there is a column called CreatedBy, showing the name of the person who created the campaign, and a column called ApprovedBy, showing the name of the person who approved the campaign.\n",
        "# If a user queries information specifying the name of a person, use the CreatedBy column if the focus is on creation, and the ApprovedBy column if the focus is on approval.\n",
        "# If a user queries information by specifying mediums, you should use the available rows for the specified mediums only to provide a comprehensive response.\n",
        "# If the name of a channel or network is mentioned in the query, use the Parent Network column for networks or the Channel column for channels to get relevant information.\n",
        "# For the Digital medium, the Parent Network and Channel columns consist of social media platforms, websites, news channels, and other organizations that operate digitally.\n",
        "# For the Print medium, these columns consist of newspaper publications.\n",
        "# Additionally, if a user mentions a city, state, or market, you should refer to the respective columns called â€”City, State, or Market.\n",
        "# For questions about spends related to parent networks or channels, ensure that the response is not zero; there must be some spends, so further investigation may be necessary.\n",
        "# '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_description = '''\n",
        "\n",
        "The data is stored in Clickhouse Database named \"default\" inside table named \"campaigns\".\n",
        "Table \"data\" consists of 17 columns. They are as follows (column_name, data_type, description):\n",
        "    \"Medium\", \"String\", \"The medium where the ad campaign takes place. It consists of 6 values: TV, Radio, Print, Digital, Outdoor and BTL.\"\n",
        "\t\"PO_Date\", \"Date\", \"The date of creation of the ad campaign. It is Null for the medium: BTL.\"\n",
        "\t\"Scheduled_Date\", \"Date\", \"The date at which the ad campaign is displayed. It is Null for the medium: Outdoor.\"\n",
        "\t\"CreatedBy\", \"String\", \"Name of the person who created the ad campaign. It is Null for the medium: BTL.\"\n",
        " \t\"ApprovedBy\", \"String\", \"Name of the person who approved the ad campaign. It is Null for the medium: BTL.\"\n",
        "\t\"Brand\", \"String\", \"The various brand names for which the ad campaign takes place.\"\n",
        "\t\"Agency\", \"String\", \"The agency or company via which the ad campaign takes place. It is Null for the medium: BTL.\"\n",
        " \t\"Channel\", \"String\", \"The channel on which the ad campaign is displayed. For medium: TV, the channel refers to TV Channels; for medium: Radio, the channel refers to Radio Channels; for medium: Print, the channel refers to Newspaper Names; for medium: Digital, the channel refers to online channels like google or facebook; for medium: Outdoor and BTL, the channel is Null.\"\n",
        "  \t\"Parent Network\", \"String\", \"The parent network of the channel. There may be many channels under a single parent network. For medium: Print, the parent network refers to the Publication Company of the Newspaper. It is Null for the medium: Outdoor and BTL.\"\n",
        "\t\"City\", \"String\", \"Name of the city. It is Null for the medium: Digital and TV.\"\n",
        "\t\"State\", \"String\", \"Name of the state. It is Null for the medium: Digital and TV.\"\n",
        "\t\"Market\", \"String\", \"Region of the ad campaign. Has 7 values: North, South, East, West, Central, All India and NaN.\"\n",
        "\t\"Ad_Lang\", \"String\", \"Language of the ad. It is Null for the medium: Digital.\"\n",
        "\t\"Caption\", \"String\", \"Caption of the ad campain. It is Null for the medium: Digital and BTL.\"\n",
        "\t\"ActivityName\", \"String\", \"It is Null for all mediums except BTL.\"\n",
        " \t\"Spot_Type\", \"String\", \"It consists of two vales: SPOT and IMPACT. It is Null for the medium: Digital, Outdoor and BTL.\"\t\n",
        " \t\"Amount\", \"Float64\", \"The amount spend on the ad campaign.\" \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juFOtVXCE_hN",
        "outputId": "3747acfd-094f-40c0-9382-9ebec2e94db7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "The data is stored in Clickhouse Database named \"default\" inside table named \"campaigns\".\n",
            "Table \"data\" consists of 17 columns. They are as follows (column_name, data_type, description):\n",
            "    \"Medium\", \"String\", \"The medium where the ad campaign takes place. It consists of 6 values: TV, Radio, Print, Digital, Outdoor and BTL.\"\n",
            "\t\"PO_Date\", \"Date\", \"The date of creation of the ad campaign. It is Null for the medium: BTL.\"\n",
            "\t\"Scheduled_Date\", \"Date\", \"The date at which the ad campaign is displayed. It is Null for the medium: Outdoor.\"\n",
            "\t\"CreatedBy\", \"String\", \"Name of the person who created the ad campaign. It is Null for the medium: BTL.\"\n",
            " \t\"ApprovedBy\", \"String\", \"Name of the person who approved the ad campaign. It is Null for the medium: BTL.\"\n",
            "\t\"Brand\", \"String\", \"The various brand names for which the ad campaign takes place.\"\n",
            "\t\"Agency\", \"String\", \"The agency or company via which the ad campaign takes place. It is Null for the medium: BTL.\"\n",
            " \t\"Channel\", \"String\", \"The channel on which the ad campaign is displayed. For medium: TV, the channel refers to TV Channels; for medium: Radio, the channel refers to Radio Channels; for medium: Print, the channel refers to Newspaper Names; for medium: Digital, the channel refers to online channels like google or facebook; for medium: Outdoor and BTL, the channel is Null.\"\n",
            "  \t\"Parent Network\", \"String\", \"The parent network of the channel. There may be many channels under a single parent network. For medium: Print, the parent network refers to the Publication Company of the Newspaper. It is Null for the medium: Outdoor and BTL.\"\n",
            "\t\"City\", \"String\", \"Name of the city. It is Null for the medium: Digital and TV.\"\n",
            "\t\"State\", \"String\", \"Name of the state. It is Null for the medium: Digital and TV.\"\n",
            "\t\"Market\", \"String\", \"Region of the ad campaign. Has 7 values: North, South, East, West, Central, All India and NaN.\"\n",
            "\t\"Ad_Lang\", \"String\", \"Language of the ad. It is Null for the medium: Digital.\"\n",
            "\t\"Caption\", \"String\", \"Caption of the ad campain. It is Null for the medium: Digital and BTL.\"\n",
            "\t\"ActivityName\", \"String\", \"It is Null for all mediums except BTL.\"\n",
            " \t\"Spot_Type\", \"String\", \"It consists of two vales: SPOT and IMPACT. It is Null for the medium: Digital, Outdoor and BTL.\"\t\n",
            " \t\"Amount\", \"Float64\", \"The amount spend on the ad campaign.\" \n",
            "\n",
            "\n",
            "### Dataset Samples\n",
            "- name: Scheduled_Date\n",
            "  type: object\n",
            "  samples:\n",
            "      - 2024-03-05\n",
            "      - 2022-10-13\n",
            "      - 2023-03-19\n",
            "- name: Brand\n",
            "  type: object\n",
            "  samples:\n",
            "      - Passion\n",
            "      - CORPORATE\n",
            "      - XTREME 200R\n",
            "- name: City\n",
            "  type: object\n",
            "  samples:\n",
            "      - UJJAIN\n",
            "      - MIDNAPORE\n",
            "      - LUCKNOW\n",
            "- name: Ad_Lang\n",
            "  type: object\n",
            "  samples:\n",
            "      - Kannada\n",
            "      - Local\n",
            "      - English\n",
            "- name: Amount\n",
            "  type: float64\n",
            "  samples:\n",
            "      - 2700.0\n",
            "      - 830860.0\n",
            "      - 11916.12\n",
            "- name: ActivityName\n",
            "  type: object\n",
            "  samples:\n",
            "      - Product Promotion\n",
            "      - Wall Wraps\n",
            "      - Product Promotion\n",
            "- name: Medium\n",
            "  type: object\n",
            "  samples:\n",
            "      - TV\n",
            "      - BTL\n",
            "      - Digital\n",
            "- name: State\n",
            "  type: object\n",
            "  samples:\n",
            "      - MADHYA PRADESH\n",
            "      - WEST BENGAL\n",
            "      - UTTAR PRADESH\n",
            "- name: Market\n",
            "  type: object\n",
            "  samples:\n",
            "      - East\n",
            "      - East\n",
            "      - Central\n",
            "- name: PO_Date\n",
            "  type: object\n",
            "  samples:\n",
            "      - 2022-09-28\n",
            "      - 2022-12-13\n",
            "      - 2023-05-22\n",
            "- name: CreatedBy\n",
            "  type: object\n",
            "  samples:\n",
            "      - Pramodk\n",
            "      - Pramodk\n",
            "      - Pramodk\n",
            "- name: Agency\n",
            "  type: object\n",
            "  samples:\n",
            "      - WALK THE TALK COMMUNICATIONS PVT. LTD.\n",
            "      - WALK THE TALK COMMUNICATIONS PVT. LTD.\n",
            "      - TLG INDIA PRIVATE LIMITED\n",
            "- name: ApprovedBy\n",
            "  type: object\n",
            "  samples:\n",
            "      - Sreekumaranp\n",
            "      - Vidhu Joshi\n",
            "      - Sreekumaranp\n",
            "- name: Spot_Type\n",
            "  type: object\n",
            "  samples:\n",
            "      - BASE\n",
            "      - BASE\n",
            "      - BASE\n",
            "- name: Parent Network\n",
            "  type: object\n",
            "  samples:\n",
            "      - TV Today Network\n",
            "      - Viacom18 Network\n",
            "      - DAINIK\n",
            "- name: Channel\n",
            "  type: object\n",
            "  samples:\n",
            "      - INDIA TODAY TELEVISION\n",
            "      - NEWS18 UP/UK\n",
            "      - DAINIK JAGRAN\n",
            "- name: Caption\n",
            "  type: object\n",
            "  samples:\n",
            "      - PREMIUM PORTFOLIO HOARDING\n",
            "      - SUPER SPLENDOR XTEC HOARDING\n",
            "      - XTREME 160R WALL WRAP\n",
            "\n",
            "### Enhanced User Query\n",
            "What is the Market for the top spent Channel?\n",
            "\n",
            "### Relevant Columns\n",
            "Market, Channel, Amount\n",
            "\n",
            "### Unique Values\n",
            "- Market: North, Multiple States, East, Central, West, South, National, nan, Gujarat, All India, North East\n",
            "- Channel: nan, GUJARAT SAMACHAR, DAINIK BHASKAR, DIVYA BHASKAR, DIVYA MARATHI, THE TELEGRAPH, EBELA, NAVBHARAT TIMES, MAHARASHTRA TIMES, SAKAL, DINAKARAN, DINAMALAR - C, MATHRUBHUMI, SAMAJ, THE PRAMEYA, PATRIKA, SANDESH, RAJASTHAN PATRIKA, LOKSATTA, GOMANTAK TIMES, PUDHARI, PRABHAT KHABAR, LOKMAT, ANANDA BAZAR PATRIKA, SAMBAD, MALAYALA MANORAMA, DAILY THANTHI, BARTAMAN, HARI BHOOMI, LOKMAT TIMES, LOKMAT SAMACHAR, SAKSHI TELUGU DAILY, PRAJAVANI, AMAR UJALA, MADHYAMAM, HINDUSTAN TIMES, EENADU, VIJAYAVANI, UDAYAVANI, VIJAY KARNATAKA, DECCAN HERALD, THE INDIAN EXPRESS, JANASATTA, TIMES OF INDIA, DAINIK SAMBAD, ASOMIYA PRATIDIN, DAINIK JANAMBHUMI, THE MIZORAM POST, VANGLAINI, UTTAR BANGA SAMBAD, THE ASSAM TRIBUNE, AJIT SAMACHAR, AJIT, JAG BANI, PUNJAB KESARI - JALANDHAR, PUNJAB KESARI, JANSATTA, BUSINESS STANDARD, DECCAN CHRONICLE, TRIBUNE, BIKE INDIA, DESHABHIMANI, PUNYA NAGARI, NAI DUNIA, DAINIK JAGRAN, THE HINDU, GURGAON TIMES - TOI, HT CITY, NOIDA TIMES - TOI, DELHI TIMES - TOI, CENTRAL CHRONICLE-CHATISG, NAGALAND POST, THE NAVHIND TIMES, POKNAPHAM, THE SHILLONG TIMES, THE STATE TIMES, NAVODAYA TIMES, I NEXT - JAGRAN, ASOMIYA KHABAR, O HERALD, GREATER KASHMIR, NAVGUJARAT SAMAY, SANDHYA TIMES, EI SAMAY, CENTRAL CHRONICLE, SANMARG (C), TELUGU VELUGU, PATRIKA (RAJ.PATRIKA GRP), RAJASTHAN PATRIKA (MAIN), SAKSHI DIST. PG - ANP, NAI DUNIA (I), THE SAMAJA - DAILY, NAVBHARAT TIMES (HIN), NAVGUJARAT TIMES, MID-BOMBAY, RAJASTHAN PATRIKA (CITY), SAKSHI, THE SAMAJA - NARI, THE ASIAN AGE, DHARITRI, SAKSHI DIST. PG - CDD, NAMASTHE TELANGANA, DIVYA HIMACHAL, SAKSHI DIST. PG - NAL, SAKSHI DIST. PG - MBN, NOIDA TIMES, DELHI TIMES, THE ECONOMIC TIMES, HT CITY DELHI WEST ZONE, HT CITY GURGAON, FINANCIAL EXPRESS (GUJ), FINANCIAL EXPRESS, MINT, HT CITY-DELHI &NCR(METRO), DAILY EXCELSIOR, NIYOMIYA BARTA, MIDDAY, DAINIK BHASKAR-(RAJ), HELLO AMRAVATI - LOKMAT, DAINIK BHASKAR-JABALPUR, NAVA BHARAT - CHATTISGARH, FAST BIKES INDIA, NAVABHARAT MAHANAGAR-NAG, JAGBANI - PUNJAB, SANMARG, NAI DUNIA CLASSIFIED, HANUMANGARH BHASKAR, DAINIK SAVERA TIMES, DAINIK JUGASANKHA, BOMBAY SAMACHAR, INDHU TAMIZH THISAL, MAHASAMUND BHASKAR-DB, JAGBANI, SANGBAD PRATIDIN, MID-DAY MUMBAI ICONS, GUJARATI MID-DAY, LUDHIANA KESARI-PUNJ.KES., DAINIK NAVAJYOTI, NAVABHARAT RAJDHANI - RAI, DINAMALAR - T, DESHDOOT, TARUN BHARAT (BELGAUM), KUTCH MITRA, THE HITAVADA, TOP GEAR, AUTO COMPONENTS INDIA, AUTO X, TURBOCHARGED, ECONOMIC TIMES- (ENG), IIT MADRAS SHAASTRA, THE HINDU - CHENNAI METRO, BANGALORE MIRROR - VK, EVO INDIA, ABP - PATRIKA, DINAMALAR - CHENNAI, PATHANKOT KESARI PUNJ.KES, HT CITY-MUMBAI, NAI DUNIA (I)-NAYIKA, S.KALIKA - ORISSA EXPRESS, THE ECONOMIC TIMES ON SAT, ABP - ANANDA PLUS, TIMES OF CHANDIGARH, ALLAHABAD TIMES - TOI, MEERUT TIMES, KANPUR TIMES - TOI, BAREILLY TIMES, LUCKNOW TIMES - TOI, PRAYAGRAJ TIMES, DEHRADUN TIMES, AGRA TIMES, LUDHIANA TRIBUNE, AMRITSAR TRIBUNE, CHANDIGARH TRIBUNE, JALANDHAR TRIBUNE, GARHWAL POST, LUDHIANA TIMES- TOI, DESH, NAVA BHARAT - MP, ARUNACHAL TIMES, DAINIK AGNIBAN, IN DINON (HINDI), KHABAR EXPRESS, HOSHIARPUR KESARI-PUN.KES, ASHI ASAVI AKHILA, DAINIK EKMAT CALENDAR, AAJ KA ANAND, SANJ SAMACHAR, RASHTRIYA CHHAVI, DESHBANDHU, BANGALORE TIMES - TOI, THE HYDERABAD MIRROR, INDORE TIMES - TOI, JAIPUR TIMES, KOCHI TIMES - TOI, KOLHAPUR TIMES - TOI, MADURAI TIMES - TOI, MANGALORE TIMES - TOI, MYSORE TIMES, NAGPUR TIMES - TOI, NASHIK TIMES - TOI, PATNA TIMES - TOI, PUNE TIMES - TOI, RAIPUR TIMES - TOI, RANCHI TIMES - TOI, SURAT TIMES - TOI, TRICHY TIMES - TOI, TRIVANDRUM TIMES - TOI, EDUCATION TIMES-VIJAYWADA, VIZAG TIMES - TOI, TIMES OF CHANDIGARH CITY, AHMEDABAD TIMES - TOI, AURANGABAD TIMES - URDU, VARANASI TIMES -TOI, BARODA TIMES - TOI, BELGAUM TIMES - TOI, BHOPAL TIMES - TOI, BOMBAY TIMES, CALCUTTA TIMES- TOI, COIMBATORE TIMES, GOA TIMES, HUBLI TIMES - TOI, RADIO MIRCHI - JAIPUR, RADIO MIRCHI - GUWAHATI, RADIO MIRCHI - DELHI, RADIO MIRCHI - LUCKNOW, RADIO MIRCHI - RAIPUR, RADIO MIRCHI - SURAT, RADIO MIRCHI - CHENNAI, RADIO MIRCHI - HYDERABAD, MY FM 94.3 (JAIPUR), RADIO CITY FM - LUCKNOW, BIG 92.7 FM (DELHI), RED FM 93.5 (DEHRADUN), RED FM 93.5 (PATNA), RADIO CITY FM - DELHI, RED FM 93.5 (LUCKNOW), RED FM 93.5 DELHI, RADIO MIRCHI - VARANASI, RADIO MIRCHI - PATNA, BIG FM 92.7 (VARANASI), RED FM 93.5 (VARANASI), RADIO CITY FM - PATNA, BIG 92.7 FM (BHUBANESWAR), RADIO MIRCHI - BARODA, RED FM 93.5 (JAIPUR), RADIO CITY FM - KARNAL, RED FM 93.5 (AHMEDABAD), RED FM 93.5-BHUBANESHWAR, RED FM 93.5 (KANPUR), RED FM 93.5 (JHANSI), BIG 92.7 FM (JALANDHAR), BIG 92.7 FM (JHANSI), BIG 92.7 FM (KANPUR), BIG 92.7 FM (PATIALA), RADIO CITY 91.9 HISAR, BIG 92.7 FM (GORAKHPUR), RED FM 93.5 (ALLAHABAD), RADIO CITY FM - PATIALA, BIG 92.7 FM (LUCKNOW), BIG 92.7 FM (AGRA), BIG 92.7 FM (ALIGARH), BIG 92.7 FM (ALLAHABAD), RADIO MIRCHI - AHMEDABAD, RED FM 93.5 AMRITSAR, BIG 92.7 FM (BARODA), BIG 92.7 FM (BAREILLY), MY FM 94.3 (AMRITSAR), MY FM 94.3 (CHANDIGARH), MY FM 94.3 (JALANDHAR), BIG 92.7 FM (CHANDIGARH), RADIO MIRCHI - MUMBAI, RED FM 93.5 (NAGPUR), RED FM 93.5 (SILIGURI), RADIO MIRCHI - NAGPUR, RED FM 93.5 (KOLKATA), RADIO MIRCHI - KOLKATA, RED FM 93.5 (GUWAHATI), RADIO MIRCHI - BANGALORE, SURYAN FM SALEM 93.5, RADIO MIRCHI - JABALPUR, SURYAN FM MADURAI 93.5, RED FM 93.5 (BANGALURU), RED FM 93.5 (BHOPAL), RADIO MIRCHI - MADURAI, RADIO MIRCHI - VIZAG, RADIO MIRCHI - COIMBATORE, RED FM 93.5 VISHAKAPATNAM, RADIO MIRCHI - BHOPAL, RED FM 93.5 (JABALPUR), RADIO MIRCHI - PUNE, SURYAN FM ERODE, RED FM 93.5 (VIJAYAWADA), RED FM 93.5 (VADODARA), RED FM 93.5 (HYDERABAD), RED FM 93.5 MUMBAI, RED FM 93.5 (PUNE), SURYAN FM COIMBATORE, RADIO MIRCHI - VIJAYAWADA, SURYAN FM CHENNAI 93.5, RADIO MIRCHI - AURANGABAD, RADIO CITY FM - PUNE, RADIO CITY FM - SURAT, RADIO CITY FM - NAGPUR, RADIO CITY FM- AHMEDNAGAR, RADIO CITY FM - VADODARA, RADIO CITY FM - NASHIK, RADIO CITY 95 FM KOLHAPUR, RADIO MIRCHI - RAJKOT, RADIO MIRCHI - NASIK, RADIO MIRCHI - KOLHAPUR, BIG 92.7 FM (ROURKELA), BIG 92.7 FM (RANCHI), BIG 92.7 FM (AGARTALA), BIG 92.7 FM (GUWAHATI), BIG 92.7 FM (JAMSHEDPUR), RED FM 94.3 MUZAFARPUR, BIG 92.7 FM (ASANSOL), EFM 91.9 FM VIJAYAWADA, RED FM 93.5 (TIRUPATI), RED FM- NELLORE, RADIO CITY FM - HYDERABAD, RED FM 93.5 (RAJAMUNDRY), UDAYA FM - VIZAG, E FM 92.7 RAJAHMUNDRY, RADIO CITY FM - VIZAG, RED FM 93.5 (WARANGAL), EFM 104.8 WARANGAL, E FM 104 TIRUPATI, RED FM 93.5 (ASANSOL), BIG 92.7 FM (KOLKATA), FEVER 104 FM (KOLKATA), FRIENDS 91.9 FM, RED FM 93.5 (HUBLI), RED FM 93.5 (GULBARGA), RADIO MIRCHI 98.3 FM, RADIO CHOKLATE 104FM(BBH), RADIO CHOKLATE (ROURKELA), 9X TASHAN, 9X JALWA, NEWS LIVE 24X7, PRAG NEWS, JAYA TV, STAR SUVARNA, RAJ TV, ZEE ANMOL CINEMA, STAR JALSHA, KAIRALI TV, DABANGG, RENGONI TV, KALAIGNAR TV, KOLKATA TV, AAKASH AATH, ETV PLUS, SONY AATH, MH1 MUSIC, WE TV, SONY WAH, SUN LIFE, J MOVIES, UDAYA TV, R PLUS, ASIANET PLUS, UDAYA MOVIES, ASIANET MOVIES, ZEE ETC BOLLYWOOD, SONY PAL, STAR UTSAV, & TV, COLORS BANGLA, E24, T NEWS, STAR MAA MOVIES, PRARTHANA TV, STAR PLUS, BHOJPURI CINEMA, B4U MOVIES, B4U MUSIC, STAR MAA, SONY SAB, STAR UTSAV MOVIES, RISHTEY, FLOWERS TV, UDAYA MUSIC, TARANG TV, BHOJPURI DHAMAKA DISHUM, ASIANET, ZING, ENTERR 10, STAR BHARAT, SUN TV, SONY MAX 2, KTV, ETV TELUGU, DANGAL TV, GEMINI TV, SONY TEN 1, MUSIC INDIA, SARTHAK TV, 10 TV, STAR MAA MUSIC, ABN ANDHRAJYOTHI, V6 NEWS, STAR MAA GOLD, SAKSHI TV, GEMINI MUSIC, NEWS 18 LOKMAT, MOVIES OK, ZEE YUVA, STAR VIJAY, 9X JHAKAAS, SONY MAX, SURYA MUSIC, ADITHYA TV, SONY TEN 1 HD, MH1 NEWS, SONY ENTERTAINMENT TV, PRAJA TV, MAZHAVIL MANORAMA, ZEE BANGLA, SONY TEN 2, MUSIC FATAFATI, STAR SUVARNA PLUS, ZEE TALKIES, IBC 24, ZEE NEWS MP-CHATTISGARH, COMEDY CENTRAL HD, INDIA TODAY TELEVISION, & PRIVE HD, PRATIDIN TIME, MOVIES NOW HD, CNN NEWS18, MNX HD, NDTV 24X7, ABP NEWS, ZEE MARATHI, ZEE HINDUSTAN, ZEE TV, UTV ACTION, STAR GOLD, MIRROR NOW, INDIA TV, TV9 KANNADA, TV9 TELUGU, REPUBLIC TV, TIMES NOW, STAR PRAVAH, & PICTURES, POLIMER, HBO HD, ZEE KANNADA, MTV, ZEE CINEMA, STAR VIJAY HD, SONY TEN 3 HD, SONY SIX, SONY SIX HD, SONY TEN 3, INDIA NEWS, STAR MAA TV HD, ZEE NEWS, MTV BEATS, BIG MAGIC GANGA, SUVARNA NEWS 24X7, SURYA MOVIES, COLORS INFINITY, NEWS 24, TARANG MUSIC, COMEDY CENTRAL, SONY PIX, STAR MOVIES, NDTV INDIA, TRAVEL XP, MOVIES NOW, HBO, STAR WORLD, SONY PIX HD, ZEE CAFE, NEWS 7, AXN, MNX, UTV MOVIES, & FLIX, INDIA NEWS - UP, SANGEET MARATHI, ROMEDY NOW HD, ROMEDY NOW, TEZ, SONY MIX, COLORS ODIA, BINDASS, TLC, 9XM, COLORS GUJARATI, POLIMER NEWS, AAJ TAK, ZEE BOLLYWOOD, COLORS KANNADA, MULTIPLEX TV, STAR GOLD - HD, STAR PLUS HD, ZEE CINEMA HD, ZEE TV HD, STAR SPORTS 1, STAR SPORTS HD 1, STAR SPORTS HINDI 1, & TV HD, & PICTURES HD, STAR SPORTS HINDI HD 1, SURYA TV, STAR SPORTS SELECT 1, STAR SPORTS SELECT HD 1, NEWS X, ZEE TAMIL, COLORS TAMIL, SUN TV HD, PUBLIC MUSIC, COLORS, ASIANET NEWS, JALSHA MOVIES, GEMINI MOVIES, ISAIYARUVI, ABP ANANDA, SIRIPPOLI, SANGEET BANGLA, TV5 NEWS, PTC NEWS, DY365, RANG, CABLE TV - JHARKAND, CABLE - Bihar, SANGEET BHOJPURI, ORISSA TV, KOLKATA LIVE, ZOOM, ZEE TELUGU, STAR VIJAY SUPER, ZEE TAMIZH, STAR GOLD 2, R BHARAT, ABP MAJHA, COLORS HD, ZEE CINEMALU, ZEE SARTHAK, STAR SPORTS SELECT 2, STAR SPORTS SELECT HD 2, STAR SPORTS 3, STAR SPORTS 2, STAR SPORTS HD 2, SUVARNA NEWS, STAR SPORTS 1 BANGLA, STAR SPORTS 1 KANNADA, STAR SPORTS TAMIL 1 SD, STAR SPORTS 1 TELUGU, NEWS LIVE, PTC PUNJABI, PUTHIYA THALAIMURAI, CNBC TV18, PUBLIC TV, THANTHI TV, MATHRUBHUMI NEWS, COLORS MARATHI, STAR SPORTS 1 HINDI, NEWS 18 INDIA, MANORAMA NEWS, WION, 24 GHANTA, ZEE PICCHAR, REPUBLIC BHARAT, PITAARA TV, TV9 MARATHI, SUN NEWS, ZEE BANGLA CINEMA, ALANKAR TV, STAR SPORTS FIRST, BIG MAGIC, ZEE ANMOL, ZEE BIOSCOPE, NEWS 18 BIHAR /JHARKHAND, ZEE CINEMA AMAGI, ZEE AMANGI BIHAR, NTV TELUGU, ABP GANGA, COLORS KANNADA HD, SONY TV HD, ORISSA TELEVISION, AIRTEL DTH HD, AIRTEL DTH SD, TATA SKY CHANNEL 100, TATA SKY HD, ET NOW, SONY MARATHI, NEWS 18 BIHAR/JHARKHAND, ASSAM TALKS, DHINCHAAK, ZEE TV - BIHAR, ZEE ACTION, ZEE CLASSIC, NEWS 18 ASSAM NORTH EAST, COLORS RISHTEY, DISCOVERY CHANNEL, NATIONAL GEOGRAPHIC CHANNEL, ZEE KERALAM, TWENTYFOUR NEWS, ZEE THIRAI, ZEE PUNJABI, ZEE NEWS BIHAR, EUROSPORT, SONY TEN 2 HD, EUROSPORT HD, SONY TEN 4 HD, SONY TEN 4, TV9 BHARATVARSH, STAR SPORTS 1 HD HINDI, DISCOVERY CHANNEL HD, SONY SAB HD, ZEE BIHAR JHARKHAND, SUN MUSIC, ZEE TELUGU - HD, ZEE BANGLA HD, NEWS18 UP/UK, MASTIII, STAR JALSHA HD, COLORS CINEPLEX, ASIANET HD, NEWS NATION, NEWS STATE - UP/UTTARAKHAND, ZEE NEWS UTTAR PRADESH/UK, REPUBLIC BANGLA, GOLDMINES, COLORS KANNADA CINEMA, TV9 GUJARATI, NEWS 18 RAJASTHAN, TV9 BANGLA, NEWS FIRST KANNADA, ND24, DD SPORTS, ZEE MARATHI HD, ZEE KANNADA HD, KAPPA TV, RAJ MUSIX TAMIL, STAR MAA MOVIES HD, ZEE RAJASTHAN NEWS, ZEE UP/UK, NEWS 18 KERALA, TATA PLAY, ZEE NEWS MP-CHHATTISGARH, NEWS18 KANNADA, SANDESH NEWS, COLORS BANGLA CINEMA, DISH TV, TIMES NOW NAVBHARAT SD, SATHIYAM TV, NEWS 18 GUJARATI, ABP ASMITA, NEWS 18 TAMIL NADU, NEWS TAMIL 24X7, COLORS CINEPLEX SUPERHITS, NGC WILD, NAT GEO WILD HD, NATIONAL GEO CHANNEL HD, COLORS CINEPLEX BOLLYWOOD, ROSE TV, SHEMAROO TV, NEWS 18 BANGLA, KANAK NEWS, D2H HOME SD, NEWS 18 ODIA, KALINGA TV, RAMDHENU, SURYA COMEDY, MTV HD, SIRI KANNADA ALL TIME, MTV BEATS HD, STAR GOLD THRILLS, SPORTS 18, SPORTS 18 KHEL, COLORS TAMIL HD, SPORTS 18 HD, NEWS 7 TAMIL, STAR SPORTS 1 TAMIL HD, STAR SPORTS 1 TELUGU HD, MAIBOLI, SAAM TV, GUJARAT SAMACHAR TV, CABLE TV - BIHAR, FACEBOOK, REVIEW SEEDING ACTIVITY, GOOGLE, INSTAGRAM, YOUTUBE, AUTOMOTIVE EXCHANGE PVT LTD, INTERACTION FEES DUMMY VENDOR, ETERNO INFOTECH PVT LTD, TWITTER, CREATIVE WEBMEDIA PRIVATE LIMITED, INTEGRAL AD SCIENCE UK LTD, NDTV CONVERGENCE LTD, D.B. CORP LIMITED (DIGITAL DIVISION), GIRNAR SOFTWARE PVT LTD, RMJ TECHNOLOGIES PRIVATE LIMITED, TIMES INTERNET LTD.(OTHER), FORK MEDIA PRIVATE LIMITED, CARTRADE TECH LIMITED, VANSUN MEDIATECH PRIVATE LIMITED, MOHALLA TECH PRIVATE LIMITED, FIFTH GEAR VENTURES LIMITED, DIGIROVERS SOLUTIONS PRIVATE LIMITED, BRANDMAP, SIMPLI5D TECHNOLOGIES PRIVATE LIMITED, MCANVAS ADVERTISING PRIVATE LIMITED, WAY2NEWS PRIVATE LIMITED, EXPONENTIAL INTERACTIVE INDIA PRIVATE LIMITED, AMAZON SELLER SERVICES PVT LTD LIMITED, NOVI DIGITAL ENTERTAINMENT PRIVATE LIMITED, ONE97 COMMUNICATIONS LIMITED, VER SE INNOVATION PRIVATE LIMITED, INTEGRAL AD SCIENCE AUSTRALIA PTY LTD, SAAVN MEDIA LIMITED, ADNEXT MEDIA, DELENTE TECHNOLOGIES PVT LTD, MXC SOLUTIONS INDIA PVT. LTD., INFLUENCER, FLIPKART, GOPROMOTO, KOFLUENCE TECH CPV PRIVATE LIMITED, DIGILLENCE SOLUTIONS PRIVATE LIMITED, AUTOPORTAL, MOBILE SMS, SOCIAL SAMOSA, HOTSTAR, GLANCE DIGITAL EXPERIENCE PVT LTD, ROOTER SPORTS TECHNOLOGIES PRIVATE LIMITED\n",
            "- Amount: \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def generate_prompt(df_description, df, enhanced_question, relevant_columns, unique_values):\n",
        "    # Initialize the prompt with a description of the dataset\n",
        "    prompt = df_description\n",
        "\n",
        "    # Add random samples from the dataset for each column\n",
        "    prompt += \"\\n\\n### Dataset Samples\\n\"\n",
        "    for col in df.columns:\n",
        "        # Get random samples from the column, ignoring NaN values\n",
        "        samples = df[col].dropna().sample(n=3, random_state=1).tolist()\n",
        "        samples_str = \"\\n      - \".join(map(str, samples))\n",
        "        prompt += f\"- name: {col}\\n  type: {df[col].dtype}\\n  samples:\\n      - {samples_str}\\n\"\n",
        "\n",
        "    # Add the enhanced user query\n",
        "    prompt += \"\\n### Enhanced User Query\\n\"\n",
        "    prompt += f\"{enhanced_question}\\n\"\n",
        "\n",
        "    # Add relevant columns\n",
        "    prompt += \"\\n### Relevant Columns\\n\"\n",
        "    prompt += f\"{', '.join(relevant_columns)}\\n\"\n",
        "\n",
        "    # Add unique values for relevant columns\n",
        "    prompt += \"\\n### Unique Values\\n\"\n",
        "    for col in relevant_columns:\n",
        "        prompt += f\"- {col}: {', '.join(map(str, unique_values.get(col, [])))}\\n\"\n",
        "\n",
        "\n",
        "    return prompt\n",
        "\n",
        "\n",
        "# Generate the prompt\n",
        "prompt = generate_prompt(df_description, df, enhanced_question, relevant_columns, unique_values)\n",
        "print(prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {
        "id": "OvF2GxfTvh3p"
      },
      "outputs": [],
      "source": [
        "import clickhouse_connect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "2b4zdlTvvsdr",
        "outputId": "75529893-fe26-461d-8d2a-8d60b513be26"
      },
      "outputs": [],
      "source": [
        "client = clickhouse_connect.get_client(host=\"localhost\", port=8123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {
        "id": "PA32ZWoiwrwh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<clickhouse_connect.driver.query.QueryResult object at 0x1581d2780>\n"
          ]
        }
      ],
      "source": [
        "query = \"\"\"SELECT name AS column_name, type AS data_type FROM system.columns WHERE table = 'campaigns' AND database = 'default'\"\"\"\n",
        "\n",
        "result = client.query(query)\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_df = client.query_df(query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Scheduled_Date',\n",
              " 'Brand',\n",
              " 'City',\n",
              " 'Ad_Lang',\n",
              " 'Amount',\n",
              " 'ActivityName',\n",
              " 'Medium',\n",
              " 'State',\n",
              " 'Market',\n",
              " 'PO_Date',\n",
              " 'CreatedBy',\n",
              " 'Agency',\n",
              " 'ApprovedBy',\n",
              " 'Spot_Type',\n",
              " 'Parent Network',\n",
              " 'Channel',\n",
              " 'Caption']"
            ]
          },
          "execution_count": 327,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_df['column_name'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of rows: 1787621\n"
          ]
        }
      ],
      "source": [
        "# Query to get the total number of rows in the table\n",
        "total_rows_query = \"SELECT COUNT(*) AS total_rows FROM campaigns\"\n",
        "total_rows_result = client.query(total_rows_query)\n",
        "\n",
        "# Extract the total row count from the result\n",
        "total_rows = total_rows_result.result_rows[0][0]  # Assuming result_rows returns a list of tuples\n",
        "print(f\"Total number of rows: {total_rows}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated SQL Code:\n",
            " ```sql\n",
            "SELECT\n",
            "  Market,\n",
            "  Channel,\n",
            "  SUM(Amount) AS TotalAmount\n",
            "FROM campaigns\n",
            "GROUP BY\n",
            "  Market,\n",
            "  Channel\n",
            "ORDER BY\n",
            "  TotalAmount DESC\n",
            "LIMIT 1;\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "sql_prompt = \"\"\"\n",
        "Using the information provided below, generate a precise SQL query to be executed on the 'campaigns' table in ClickHouse. Ensure the query:\n",
        "1. Retrieves only distinct values where applicable.\n",
        "2. Utilizes the relevant columns specified.\n",
        "3. Avoids any key errors by using provided unique values.\n",
        "4. Correctly reflects the userâ€™s query by focusing on the specific requirements mentioned.\n",
        "{}\n",
        "\"\"\".format(prompt)\n",
        "\n",
        "# Request SQL code generation from the AI model\n",
        "sql_code = llm.invoke(sql_prompt)\n",
        "\n",
        "# Print the generated SQL code\n",
        "print(\"Generated SQL Code:\\n\", sql_code)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned SQL Code:\n",
            " SELECT\n",
            "  Market,\n",
            "  Channel,\n",
            "  SUM(Amount) AS TotalAmount\n",
            "FROM campaigns\n",
            "GROUP BY\n",
            "  Market,\n",
            "  Channel\n",
            "ORDER BY\n",
            "  TotalAmount DESC\n",
            "LIMIT 1;\n"
          ]
        }
      ],
      "source": [
        "# Clean up the SQL code by removing unnecessary formatting\n",
        "import re\n",
        "\n",
        "def clean_sql_code(sql_code):\n",
        "    # Remove backticks and any extra characters\n",
        "    cleaned_code = re.sub(r'```sql|```', '', sql_code).strip()\n",
        "    return cleaned_code\n",
        "\n",
        "# Clean the SQL code\n",
        "cleaned_sql_code = clean_sql_code(sql_code)\n",
        "\n",
        "print(\"Cleaned SQL Code:\\n\", cleaned_sql_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query Result:\n",
            " <clickhouse_connect.driver.query.QueryResult object at 0x15806cd70>\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    result = client.query(cleaned_sql_code)\n",
        "    print(\"Query Result:\\n\", result)\n",
        "except Exception as e:\n",
        "    print(\"An error occurred while executing the SQL query:\", str(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[\"North\", null, 40648499795.36029]]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "result_data = result.result_rows\n",
        "result_json = json.dumps(result_data)\n",
        "print(result_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Framed Answer:\n",
            " The top-performing combination of market and channel in terms of total amount is \"North\" market with no specific channel specified. This combination has generated a total amount of $40,648,499,795.36.\n"
          ]
        }
      ],
      "source": [
        "# Create a prompt for the LLM to frame the answer\n",
        "answer_prompt_template = \"\"\"\n",
        "You are an assistant that provides clear and concise answers based on query results.\n",
        "\n",
        "The SQL query executed was:\n",
        "{sql_code}\n",
        "\n",
        "The result obtained from the database is:\n",
        "{result}\n",
        "\n",
        "Please frame an answer to present this result in a user-friendly manner, explaining the information in simple terms and addressing the user's query based on the result provided.\n",
        "\"\"\"\n",
        "\n",
        "answer_prompt = answer_prompt_template.format(sql_code=cleaned_sql_code, result=result_json)\n",
        "\n",
        "# Request the answer framing from the LLM\n",
        "try:\n",
        "    answer = llm.invoke(answer_prompt)\n",
        "    print(\"Framed Answer:\\n\", answer)\n",
        "except Exception as e:\n",
        "    print(\"An error occurred while generating the answer:\", str(e))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
